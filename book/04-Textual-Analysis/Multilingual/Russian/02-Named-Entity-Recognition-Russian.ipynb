{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition for Russian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: lightblue; padding: 10px\">\n",
    "<p class=\"title\">Note</p>\n",
    "This section, \"Working in Languages Beyond English,\" is co-authored with <a href=\"http://www.quinndombrowski.com/\">Quinn Dombrowski</a>, the Academic Technology Specialist at Stanford University and a leading voice in multilingual digital humanities. I'm grateful to Quinn for helping expand this textbook to serve languages beyond English. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we're going to learn about a text analysis method called *Named Entity Recognition* (NER) as applied to Russian. This method will help us computationally identify people, places, and things (of various kinds) in a text or collection of texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example text for Russian is *Яблони цветут* from *Новые люди* by Зинаида Николаевна Гиппиус [from Библиотека русской и советской классики](https://ruslit.traumlibrary.net/book/gippius-ss15-01/gippius-ss15-01.html). (Thanks to Katherine Bowers for the text referral.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here's a preview of spaC's NER tagging *Яблони цветут*.**\n",
    "\n",
    "If you compare the results to the [English example](Named-Entity-Recognition), you'll notice that the Russian NER is much less good at recognizing entities, and is especially bad ata distinguishing different kinds of entities, like ORG vs LOC. You need a lot of examples to train a model to distinguish different entity types; currently, English is the only model that does a decent job of it.\n",
    "\n",
    "You can read more about the [data sources used to train Russian](https://spacy.io/models/ru) on the spaCy model page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll",
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">ает, особенно теперь, ночью… Старуха, моя кухарка, спит. И главное, ничего не сделается от того, что я закину веревку на крюк. Ее можно снять и снести обратно в переднюю. Даже если я петлю сделаю – и то ничего ровно не случится, ведь не повешусь же, ведь не должен же я, оттого что сделаю петлю, непременно повеситься? Это так ужасно, так некрасиво… Как я далеко от \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Марты\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       "!.. Но разве я в самом деле?.. Нет, нет, я только попробую, никто не узнает, а я попробую…</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(document, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER with spaCy\n",
    "If you've already used the pre-processing notebook for this language, you can skip the steps for installing spaCy and downloading the language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install spaCy\n",
    "Russian models are only available starting in spaCy 3.0. \n",
    "\n",
    "If you run into errors because spaCy 2.x is installed, you can run `!pip uninstall spacy -y` first, then run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to import `spacy` and `displacy`, a special spaCy module for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 600\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to import the `Counter` module for counting people, places, and things, and the `pandas` library for organizing and displaying data (we're also changing the pandas default max row and column width display setting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to download the Russian-language model (`ru_core_news_md`), which will be processing and making predictions about our texts. You can read more about the [data sources used to train Russian](https://spacy.io/models/ru) on the spaCy model page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-md==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_md-3.7.0/ru_core_news_md-3.7.0-py3-none-any.whl (41.9 MB)\n",
      "     ---------------------------------------- 0.0/41.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/41.9 MB 4.3 MB/s eta 0:00:10\n",
      "     ---------------------------------------- 0.4/41.9 MB 4.9 MB/s eta 0:00:09\n",
      "      --------------------------------------- 0.7/41.9 MB 5.5 MB/s eta 0:00:08\n",
      "      --------------------------------------- 0.9/41.9 MB 5.4 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 1.2/41.9 MB 5.4 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 1.5/41.9 MB 5.6 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 2.0/41.9 MB 6.3 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 2.5/41.9 MB 7.0 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.2/41.9 MB 7.7 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.8/41.9 MB 8.3 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 3.8/41.9 MB 7.9 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 4.1/41.9 MB 7.8 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 4.4/41.9 MB 7.5 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 4.8/41.9 MB 7.6 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 5.2/41.9 MB 7.5 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 5.4/41.9 MB 7.3 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 5.7/41.9 MB 7.2 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 6.1/41.9 MB 7.3 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 6.5/41.9 MB 7.5 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 6.8/41.9 MB 7.5 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 7.0/41.9 MB 7.2 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 7.3/41.9 MB 7.2 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 7.6/41.9 MB 7.2 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 7.9/41.9 MB 7.2 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 8.2/41.9 MB 7.2 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 8.5/41.9 MB 7.2 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 8.7/41.9 MB 7.0 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 9.0/41.9 MB 7.0 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 9.4/41.9 MB 7.1 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 9.8/41.9 MB 7.1 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 10.3/41.9 MB 7.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 10.8/41.9 MB 7.6 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 11.2/41.9 MB 7.7 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 11.5/41.9 MB 7.8 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 11.9/41.9 MB 7.8 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 12.1/41.9 MB 7.7 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 12.6/41.9 MB 7.5 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 12.9/41.9 MB 7.4 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 13.2/41.9 MB 7.3 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 13.6/41.9 MB 7.2 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 14.0/41.9 MB 7.4 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 14.3/41.9 MB 7.3 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 14.8/41.9 MB 7.4 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 15.2/41.9 MB 7.4 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 15.5/41.9 MB 7.5 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 15.8/41.9 MB 7.5 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 16.1/41.9 MB 7.4 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 16.5/41.9 MB 7.4 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 17.0/41.9 MB 7.5 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 17.2/41.9 MB 7.7 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 17.5/41.9 MB 7.7 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 17.8/41.9 MB 7.6 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 18.2/41.9 MB 7.6 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 18.7/41.9 MB 8.1 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 19.4/41.9 MB 8.3 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 19.8/41.9 MB 8.4 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 20.1/41.9 MB 8.2 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 20.4/41.9 MB 8.2 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 20.7/41.9 MB 8.0 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 20.9/41.9 MB 7.9 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 21.1/41.9 MB 7.8 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 21.6/41.9 MB 7.7 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 22.1/41.9 MB 8.0 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 22.6/41.9 MB 8.2 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 22.9/41.9 MB 8.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 23.3/41.9 MB 8.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 23.6/41.9 MB 8.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 24.0/41.9 MB 8.0 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 24.3/41.9 MB 7.9 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 24.6/41.9 MB 7.9 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 25.0/41.9 MB 7.9 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 25.3/41.9 MB 7.8 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 25.7/41.9 MB 7.8 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 25.9/41.9 MB 7.7 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 26.3/41.9 MB 7.9 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 26.9/41.9 MB 8.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 27.4/41.9 MB 8.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 27.8/41.9 MB 8.3 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 28.2/41.9 MB 8.3 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 28.4/41.9 MB 8.3 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 28.8/41.9 MB 8.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 29.3/41.9 MB 8.0 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 29.5/41.9 MB 7.8 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 29.8/41.9 MB 7.7 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 30.2/41.9 MB 7.8 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 30.8/41.9 MB 8.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 31.2/41.9 MB 8.3 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 31.6/41.9 MB 8.2 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 32.0/41.9 MB 8.3 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 32.2/41.9 MB 8.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 32.7/41.9 MB 8.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 33.1/41.9 MB 8.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 33.5/41.9 MB 8.2 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 33.7/41.9 MB 8.0 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 34.1/41.9 MB 8.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 34.4/41.9 MB 8.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 34.7/41.9 MB 8.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 35.2/41.9 MB 8.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 35.9/41.9 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 36.6/41.9 MB 8.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 37.0/41.9 MB 8.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 37.3/41.9 MB 8.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 37.7/41.9 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.0/41.9 MB 8.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.3/41.9 MB 8.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.6/41.9 MB 8.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 38.8/41.9 MB 8.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 39.0/41.9 MB 8.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 39.3/41.9 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 39.6/41.9 MB 8.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.0/41.9 MB 8.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.3/41.9 MB 8.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.7/41.9 MB 8.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.1/41.9 MB 7.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.4/41.9 MB 7.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.8/41.9 MB 7.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/41.9 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/41.9 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/41.9 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/41.9 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/41.9 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/41.9 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/41.9 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/41.9 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/41.9 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 41.9/41.9 MB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from ru-core-news-md==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from ru-core-news-md==3.7.0) (1.2.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-md==3.7.0) (0.7.2)\n",
      "Requirement already satisfied: docopt-ng>=0.6 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-md==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in c:\\users\\minh\\anaconda3\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-md==3.7.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (1.24.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\minh\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\minh\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-md==3.7.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ru_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is downloaded, we need to load it. There are two ways to load a spaCy language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** We can import the model as a module and then load it from the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ru_core_news_md\n",
    "nlp = ru_core_news_md.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** We can load the model by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('ru_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just downloaded the model for the first time, it's advisable to use Option 1. Then you can use the model immediately. Otherwise, you'll likely need to restart your Jupyter kernel (which you can do by clicking Kernel -> Restart Kernel.. in the Jupyter Lab menu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to process our `document` with the loaded NLP model. Most of the heavy NLP lifting is done in this line of code.\n",
    "\n",
    "After processing, the `document` object will contain tons of juicy language data — named entities, sentence boundaries, parts of speech — and the rest of our work will be devoted to accessing this information.\n",
    "\n",
    "In the cell below, we open and the example document. Then we run`nlp()` on the text and create our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../texts/ru.txt'\n",
    "text = open(filepath, encoding='utf-8').read()\n",
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the named entities in our `document` can be found in the `document.ents` property. If we check out `document.ents`, we can see all the entities from the example document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Петербурге,\n",
       " Петербурге,\n",
       " Володя,\n",
       " Москву,\n",
       " Володя,\n",
       " Сыромятников,\n",
       " Маремьянов,\n",
       " Москву,\n",
       " экономка,\n",
       " Москве,\n",
       " Малой Никитской,\n",
       " Володя,\n",
       " Москве,\n",
       " Листьев,\n",
       " Коренева,\n",
       " Коренева,\n",
       " Кореневой,\n",
       " Марфа,\n",
       " Марта,\n",
       " Марта,\n",
       " Володя,\n",
       " Марта,\n",
       " Марты,\n",
       " Марта,\n",
       " Марта,\n",
       " Голос,\n",
       " Марта,\n",
       " Мартой,\n",
       " Марты,\n",
       " Володя,\n",
       " Марфу Кореневу,\n",
       " Марту,\n",
       " Марте,\n",
       " Марта,\n",
       " Володя,\n",
       " Марту,\n",
       " Марта,\n",
       " Марта,\n",
       " Марта,\n",
       " Марта,\n",
       " Небо,\n",
       " Марта,\n",
       " Марта,\n",
       " Марты,\n",
       " Марта,\n",
       " Пора,\n",
       " Марта,\n",
       " Москвы,\n",
       " Марте,\n",
       " Петербурге,\n",
       " Марты)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the named entities in `document.ents` contains [more information about itself](https://spacy.io/usage/linguistic-features#accessing), which we can access by iterating through the `document.ents` with a simple `for` loop.\n",
    "\n",
    "For each `named_entity` in `document.ents`, we will extract the `named_entity` and its corresponding `named_entity.label_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Петербурге LOC\n",
      "Петербурге LOC\n",
      "Володя PER\n",
      "Москву LOC\n",
      "Володя PER\n",
      "Сыромятников PER\n",
      "Маремьянов PER\n",
      "Москву LOC\n",
      "экономка PER\n",
      "Москве LOC\n",
      "Малой Никитской LOC\n",
      "Володя PER\n",
      "Москве LOC\n",
      "Листьев PER\n",
      "Коренева PER\n",
      "Коренева PER\n",
      "Кореневой PER\n",
      "Марфа PER\n",
      "Марта PER\n",
      "Марта PER\n",
      "Володя PER\n",
      "Марта PER\n",
      "Марты PER\n",
      "Марта PER\n",
      "Марта PER\n",
      "Голос PER\n",
      "Марта PER\n",
      "Мартой PER\n",
      "Марты PER\n",
      "Володя PER\n",
      "Марфу Кореневу PER\n",
      "Марту PER\n",
      "Марте PER\n",
      "Марта PER\n",
      "Володя PER\n",
      "Марту PER\n",
      "Марта PER\n",
      "Марта PER\n",
      "Марта PER\n",
      "Марта PER\n",
      "Небо PER\n",
      "Марта PER\n",
      "Марта PER\n",
      "Марты PER\n",
      "Марта PER\n",
      "Пора PER\n",
      "Марта LOC\n",
      "Москвы LOC\n",
      "Марте PER\n",
      "Петербурге LOC\n",
      "Марты PER\n"
     ]
    }
   ],
   "source": [
    "for named_entity in document.ents:\n",
    "    print(named_entity, named_entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract just the named entities that have been identified as `PER` (person), we can add a simple `if` statement into the mix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Володя\n",
      "Володя\n",
      "Сыромятников\n",
      "Маремьянов\n",
      "экономка\n",
      "Володя\n",
      "Листьев\n",
      "Коренева\n",
      "Коренева\n",
      "Кореневой\n",
      "Марфа\n",
      "Марта\n",
      "Марта\n",
      "Володя\n",
      "Марта\n",
      "Марты\n",
      "Марта\n",
      "Марта\n",
      "Голос\n",
      "Марта\n",
      "Мартой\n",
      "Марты\n",
      "Володя\n",
      "Марфу Кореневу\n",
      "Марту\n",
      "Марте\n",
      "Марта\n",
      "Володя\n",
      "Марту\n",
      "Марта\n",
      "Марта\n",
      "Марта\n",
      "Марта\n",
      "Небо\n",
      "Марта\n",
      "Марта\n",
      "Марты\n",
      "Марта\n",
      "Пора\n",
      "Марте\n",
      "Марты\n"
     ]
    }
   ],
   "source": [
    "for named_entity in document.ents:\n",
    "    if named_entity.label_ == \"PER\":\n",
    "        print(named_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER with Long Texts or Many Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "number_of_chunks = 80\n",
    "\n",
    "chunk_size = math.ceil(len(text) / number_of_chunks)\n",
    "\n",
    "text_chunks = []\n",
    "\n",
    "for number in range(0, len(text), chunk_size):\n",
    "    text_chunk = text[number:number+chunk_size]\n",
    "    text_chunks.append(text_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_documents = list(nlp.pipe(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get People"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract and count the people, we will use an `if` statement that will pull out words only if their \"ent\" label matches \"PER.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Марта</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Володя</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Марты</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Коренева</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Марту</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Марте</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Сыромятников</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Маремьянов</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>экономка</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Листьев</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Кореневой</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Марфа</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Голос</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Мартой</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Марфу Кореневу</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Полоцк</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Небо</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Пора</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         character  count\n",
       "0            Марта     13\n",
       "1           Володя      6\n",
       "2            Марты      4\n",
       "3         Коренева      2\n",
       "4            Марту      2\n",
       "5            Марте      2\n",
       "6     Сыромятников      1\n",
       "7       Маремьянов      1\n",
       "8         экономка      1\n",
       "9          Листьев      1\n",
       "10       Кореневой      1\n",
       "11           Марфа      1\n",
       "12           Голос      1\n",
       "13          Мартой      1\n",
       "14  Марфу Кореневу      1\n",
       "15          Полоцк      1\n",
       "16            Небо      1\n",
       "17            Пора      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = []\n",
    "\n",
    "for document in chunked_documents:\n",
    "    for named_entity in document.ents:\n",
    "        if named_entity.label_ == \"PER\":\n",
    "            people.append(named_entity.text)\n",
    "\n",
    "people_tally = Counter(people)\n",
    "\n",
    "df = pd.DataFrame(people_tally.most_common(), columns=['character', 'count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract and count places, we can follow the same model as above, except we will change our `if` statement to check for \"ent\" labels that match \"LOC.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Петербурге</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Москву</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Москве</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Малой Никитской</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Марта</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Москвы</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             place  count\n",
       "0       Петербурге      3\n",
       "1           Москву      2\n",
       "2           Москве      2\n",
       "3  Малой Никитской      1\n",
       "4            Марта      1\n",
       "5           Москвы      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places = []\n",
    "for document in chunked_documents:\n",
    "    for named_entity in document.ents:\n",
    "        if named_entity.label_ == \"LOC\":\n",
    "            places.append(named_entity.text)\n",
    "\n",
    "places_tally = Counter(places)\n",
    "\n",
    "df = pd.DataFrame(places_tally.most_common(), columns=['place', 'count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NER in Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "\n",
    "def get_ner_in_context(keyword, document, desired_ner_labels= False):\n",
    "    \n",
    "    if desired_ner_labels != False:\n",
    "        desired_ner_labels = desired_ner_labels\n",
    "    else:\n",
    "        desired_ner_labels = ['PER', 'ORG', 'LOC']  \n",
    "        \n",
    "    #Iterate through all the sentences in the document and pull out the text of each sentence\n",
    "    for sentence in document.sents:\n",
    "        #process each sentence\n",
    "        sentence_doc = nlp(sentence.text)\n",
    "        for named_entity in sentence_doc.ents:\n",
    "            #Check to see if the keyword is in the sentence (and ignore capitalization by making both lowercase)\n",
    "            if keyword.lower() in named_entity.text.lower()  and named_entity.label_ in desired_ner_labels:\n",
    "                #Use the regex library to replace linebreaks and to make the keyword bolded, again ignoring capitalization\n",
    "                #sentence_text = sentence.text\n",
    "            \n",
    "                sentence_text = re.sub('\\n', ' ', sentence.text)\n",
    "                sentence_text = re.sub(f\"{named_entity.text}\", f\"**{named_entity.text}**\", sentence_text, flags=re.IGNORECASE)\n",
    "\n",
    "                display(Markdown('---'))\n",
    "                display(Markdown(f\"**{named_entity.label_}**\"))\n",
    "                display(Markdown(sentence_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "– Да, так вы удивились, что я **Марта**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Я не мог убедить себя, что **Марта** – барышня, а я ей говорю комплименты."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Не успел я сесть на свою скамейку и опомниться, как сейчас же, сию минуту я услышал знакомый шорох, **Марта** подошла к изгороди и сказала:  – Здравствуйте.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "– А я знаю, где сегодня спрячется солнце, – сказала **Марта**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Я вспомнил, как и мне в эти дни звук рояля казался резким.  – Только… – продолжала **Марта**, – вы не сердитесь, но часто вы играете такое составное, из многих разных нот, а всего-то нет."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Я вдруг вспомнил, что не видал ее улыбки.  – Вы никогда не смеетесь, **Марта**? – спросил я.  – Солнце заходит, – серьезно ответила она."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "не, о яблонях, о Марте, и что **Марта** для меня – оживший сад, то же, что небо и ветер…"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "– Простите, **Марта**, – сказал я."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Но платье, теперь я уже не мог сомневаться, было не белое, а чуть-чуть розовое.  – Мы будем ждать, – сказала **Марта**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "нет светлеть, а небо станет выше – тогда они распустятся.  – Отчего вы такая, **Марта**? – спросил я."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "– И я люблю вас, **Марта**, – сказал я."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "– Надо спокойнее, спокойнее, – проговорила **Марта**, положив бледную руку на мою."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "– Первый цветок распустился, – сказала **Марта**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**PER**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Когда прошло время, и все кругом нас стало яснее и холоднее, небо позеленело, и утренние сумерки спустились, – я взглянул близко в лицо Марты, **Марта** сидела все в том же положении, прижавшись ко мне."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LOC**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Она осталась на скамейке и не смотрела на меня.  – Прощай, **Марта**, – сказал я.  – Прощай."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for document in chunked_documents:\n",
    "    get_ner_in_context('Марта', document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
